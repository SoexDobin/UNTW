# 7장

## 통계 분석의 이해
1. 통계 분석의 개요
2. 변수와 측정
3. 평균 분산 및 표준편차
4. 통계적 가설 검정
5. 상관관계 분석
6. 요인 분석
7. 회귀 분석

## 기술 통계 : 방대한 자료를 요약하는 방법
* 평균
* 분산
* 비율

## 추측 통계 : 관측한 표본을 이용한 불확실한 모집단 특성을 추론
* 회귀 분석
* 시계열 분석

## 모형화의 개념
* 문제의 의도적 단순화
* 복잡한 현실의 구조화
* 연구 대상 변수들 간의 관계
* 연구 대상의 단순화

## 변수
* ``` Y = a + bX ```
* Y : 종속 변수
* X : 독립 변수
* a, b : 모수

## 척도 유형
* 명목 척도 : 상징적 의미를 숫자로 부여하여 분류
  - 0, 덧셈, 뺄셈 이라는 개념이 없음 (ex. 1. 남, 2. 여/ 1. 수도권, 2. 비수도원)
* 서열 척도 : 측정 대상들의 우열 관계를 특정 지음
  - 0, 덧셈, 뺄셈 이라는 개념이 없음 (ex. 1. 1등 99점, 2. 2등 84점)
  - 순위 변경 없으면 수치를 변환해도 상관없음
* 등간 척도 : 측정치의 차이가 동일한 간격을 가지는 척도
  - 0의 개념이 없음 덧셈, 뺄셈, 평균계산 가능 (ex. 1. 월 23도, 2. 화 27도)
* 비율 척도 : 비율 분석이 가능한 척도 
  - 0 개념이 있으며, 산수가 가능함 (ex. 무게, 가격, 시장 점유율, 매출액 등)

## 평균, 분산, 표준편차
``` 편차 = 자료값 - 평균 ```
1. **평균 : 모집단이 지니고있는 양적 구조의 특성치인 대표치를 나타냄**
2. **분산 : 평균을 중심으로 흩어진 정도의 제곱 값 (편차 제곱의 평균)**
3. **표준편차 : 평균을 중심으로 흩어진 정도의 원래 값을 말함 (분산의 루트 값)**

## 통계적 검정의 유형 및 적용

## t-검정의 단계 : 두 집단 간의 평균 차이 여부를 검정하는 방법
1. 가설 설정
  - 귀두 가설 : ex.) (a = b) (c >= d)
  - 대립 가설 : ex.) (a != b) (c < d)
2. 기준치 t값 설정 단계
3. t값 산정 단계
4. 기각역 결정 단계

### 1. 단일표본 t-검정 : 표본이 1가지인 경우
* 예시1
![image](https://github.com/SoexDobin/UNTW/assets/56966606/6b176048-d148-49c5-9b64-b5af3ad09ad5)
* 예시2
![image](https://github.com/SoexDobin/UNTW/assets/56966606/510a9994-f150-4bab-a099-6fb5bdb7c652)

### 2. 독립표본 t-검정 : 
* 공식 : 평균 차이 / 표준 오차

* 평균 차이 = (A평균 - B평균)
* 표준 오차 = ({A 표준편차}^2 / 표본 수) + ({B 표준편차}^2 / 표본 수)^2
* t-검정 통계량 = 평균 차이 / 표준 오차

* 예시
![image](https://github.com/SoexDobin/SmartDeviceWiki/assets/56966606/5dbada6e-77a8-4f06-94fb-8062a685ad35)

### 3. 대응표본 t-검정 : 2개의 대응되는 짝 표본을 추출하여 두표본과 모집단 차이를 구함
* 예시
![image](https://github.com/SoexDobin/UNTW/assets/56966606/ece3659c-9329-46e3-9b4c-4e7fcdd9d4da)

```
t 검정은 모집단의 평균을 알거나,
평균과 분산을 알고 있을 경우
표본의 평균이 모집단의 평균가 같은지
여부를 검정하는 방법
```

## t-검정의 단계 : 두 집단 간의 평균 차이 여부를 검정하는 방법

## F- 검정 분산 비교를 위한 통계적 검정 방법
* F-검정 공식 : ```F = (MSB / MSE)```

* 그룹간 변동(SSB) = (A평균 - {모든 집단 평균의 평균})^2 * (집단표본 수) + ...
* 그룹 간 평균 제곱(MSB) = SSB / (집단의 수 - 1)
* 그룹 내 변동(SSW) = ([{A그룹 표본 수} - 1] * {A 그룹 평균}) + ...
* 그룹 내 평균 제곱(MSE) = SSW / ( {모든 집단 표본 수} - 집단의 수)

* 예시 
![image](https://github.com/SoexDobin/UNTW/assets/56966606/ca5982c7-1cfd-4e80-9ace-782e5a9f30ee)

## 카이제곱검정 
* 카이제곱검정 공식 : ```x^2 = Σ((집단 표본 수 - 집단 평균(기대 빈도))^2 / 집단 평균(기대 빈도))```

* 예시 
![image](https://github.com/SoexDobin/SmartDeviceWiki/assets/56966606/1b456729-edcd-4bc4-bb64-914ec9e032cd)

# 8장 

## 소셜 데이터 분석 
* 텍스트 마이닝
* 소셜 네트워크 분석
* 웹마이닝
* 오피니언마이닝

## 정형데이터 분석 기법
1. 연관관계 분석
2. 의사결정나무
3. 인공신경망
4. 사례기반추론

## 데이터마이닝 기법
1. 사례기반추론
2. 군집분석
3. 인공신경망
4. 의사결정나무

## 연관관계 분석 유형
* 지지도(Support): 두 개 이상의 항목이 동시에 발생하는 비율을 나타냅니다. 지지도는 연관분석에서 가장 기본적인 개념으로, 특정 항목들 간의 동시 발생 여부를 측정합니다.
* 신뢰도(Confidence): 조건 항목 집합이 주어졌을 때 결과 항목이 발생하는 조건부 확률을 나타냅니다. 신뢰도는 조건 항목들과 결과 항목 간의 연관성 강도를 측정합니다.
* 향상도(Lift): 두 개 이상의 항목 간의 연관성이 우연에 비해 얼마나 더 강한지를 나타냅니다. 향상도 값이 1보다 크면 양의 상관관계를, 1보다 작으면 음의 상관관계를 나타냅니다.
* 신뢰도(confidence) : 지지도와 신뢰도를 축으로 하는 점들로 구성되며, 연관분석 결과를 보다 직관적으로 이해할 수 있도록 도와줍니다.
* 특이도(Specificity): 조건 항목 집합이 없을 때 결과 항목이 발생하지 않는 비율을 나타냅니다. 특이도는 결과 항목이 발생하지 않는 확률을 측정하여 결과 항목과의 연관성을 나타냅니다.

## 음의 상관관계에서의 값 도출
* A가 존재하여 B에서 도출되는 값은 1보다 작으면 0보다 커야 한다.

## 의사결정나무 장점
* 모델의 이해가 용이하다.
* 중요한 변수의 선정이 용이하다.
* 듄로 변환이 가능하다.
* 분석 결과의 이해가 쉽다.
* 데이터 전처리 요구 감소
* 비선형(복잡한) 관계 모델링 가능

## 의사결정나무 알고리즘
* ID3 (Iterative Dichotomiser 3) : 정보 이론 기반으로 동작하며, 엔트로피를 사용하여 분기할 조건을 선택
* C4.5 : ID3 알고리즘의 개선된 버전으로, 엔트로피 대신 정보 이득을 사용하여 분기를 수행
* CART (Classification and Regression Trees) : 분류와 회귀 문제에 모두 적용할 수 있는 의사결정나무 알고리즘. CART는 지니 지수(Gini Index)를 사용하여 분기할 조건을 선택
* CHAID (Chi-squared Automatic Interaction Detection) : 범주형 타깃 변수와 범주형 예측 변수 간의 관계를 분석하는 의사결정나무 알고리즘. CHAID는 카이제곱 검정을 사용하여 분기할 조건을 선택

## 인공신경망 관련 용어
1. 뉴련(Neuron)
2. 가중치(weight)
3. 편향(Bias)
4. 활성화 함수(Activation Function)
5. 입력층(Input layer)
6. 은닉층(Hidden Layer)
7. 출력층(Output Layer)
8. 손실 함수(Loss Function)
9. 에포크(Epoch)
10. 역전파(Backpropagation)

## 인공신경망에서 모델의 정확도를 알아보기 위한 데이터
* **테스트 데이터**

## 사례기반추론 장단점
#### 장점
1. 유연한 문제 해결: 사례기반추론은 과거의 실제 사례를 활용하기 때문에 다양한 상황과 복잡한 문제에 유연하게 대처할 수 있습니다. 새로운 문제가 발생하더라도 해당 문제와 유사한 사례를 찾아 해결 방법을 도출할 수 있습니다.

2. 학습과 적응 능력: 새로운 사례가 추가되면 기존의 사례와 비교하여 유사성을 판단하고, 필요한 경우 새로운 사례를 기반으로 시스템을 업데이트할 수 있습니다. 이를 통해 시스템은 점진적으로 학습하고 새로운 상황에 적응할 수 있습니다.

3. 인과관계 이해: 사례기반추론은 개별 사례와 해당 사례의 해결 방법을 직접적으로 연결하는 방식으로 작동합니다. 따라서 시스템은 문제 해결 과정에서 인과관계를 파악하고 설명할 수 있어 사용자가 해결 방법을 이해하고 신뢰할 수 있습니다.

#### 단점
1. 데이터 의존성: 사례기반추론은 사례 데이터에 의존하기 때문에 데이터의 품질과 양에 영향을 받습니다. 데이터의 부족이나 잘못된 데이터가 있을 경우 정확한 추론을 할 수 없을 수 있습니다.

2. 문제 복잡도: 사례기반추론은 문제의 복잡성에 따라 추론 시간이 길어지는 경향이 있습니다. 많은 사례를 비교해야 하거나 유사성을 판단하기 위해 복잡한 계산이 필요한 경우에는 성능이 저하될 수 있습니다.

3. 새로운 상황 처리의 어려움: 사례기반추론은 새로운 상황에 대한 대응이 제한적입니다. 이전에 등록된 사례와 매우 다른 상황이나 도메인에서는 적절한 해결 방법을 도출하기 어려울 수 있습니다.
